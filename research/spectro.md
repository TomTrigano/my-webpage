---
layout: page
title: Signal Processing and Machine Learning for Nuclear Spectroscopy
permalink: /research/spectro/
---

Nuclear spectroscopy signals appear frequently in security applications, decommissioning and medical imaging. For all these applications, it is of critical interest to estimate precisely the activity of radioactive sources, and to identify them, and the signal is often modeled by a filtered Poisson process. During my post-doctoral stay at the Hebrew University, I developed a time-domain model to consider gamma spectroscopic signals as a sparse regression problem, and developed an algorithm based on a thresholded version of LASSO to estimate precisely the activity of a radioactive source, even at very high counting rates. The main difficulty was to illustrate mathematically how such an approach could hold, as it is well known from compressive sensing theory that sparse reconstruction is possible only when drastic conditions on the dictionary used hold. We showed that under mild conditions, relating the intensity and the sampling frequency of the device, the activity could be estimated precisely even if standard conditions on the dictionary did not hold in practice in the case of a homogeneous Poisson process. We implemented various estimate with different sparse methods, and later on extended the previous result in the non-homogeneous setting, by plugging the estimated arrival times into a nonparametric estimation of the activity. Furthermore, we showed in that this methodology could be beneficial for pile-up correction in this framework, and provided empirical proofs that the obtained energy spectra were less distorted once the iterative reconstruction had been applied (an application example can also be found in my publications). The last remaining obstacle was the computational time, since the signals recorded in the field are usually very large. Thus, I developed in a fast algorithm for solving the related optimization procedures on very larges signals (more than several millions points), based on the use of Fast Fourier Transforms in proximal methods, which allows now to process large dataset in a very short time, without any other memory use than the one necessary to load the signal itself. The method proposed in has also the advantage to be faster by about two decades than the standard optimization programming, and can be applied for a wide class of sparse optimization problems which satisfy an homogeneity condition.

Regarding the use of compressive sensing and ML techniques in nuclear spectroscopy, it is clear that a lot remains to be done. Indeed, recent findings in the field show that even if time-domain approaches improve significantly the state of the art, they are less performant at very high counting rate. A change of paradigm is therefore necessary. A couple of years ago I started collaborating with Prof. Jonathan Manton from the university of Melbourne on the matter. The main objective in the long-run is to develop new mathematical tools to either improve the existing algorithm, or to better assess their performances. I also started in 2022 to collaborate on with Prof. Xiaoying Zheng from the Shanghai Advanced Research Institute, to introduce Deep Neural Networks (DNNs) in Nuclear Instrumentation Devices with GPUs for pile-up correction. Though the data acquisition in this field is very challenging, this lead can yield promising results.